{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd7olqKqSaPUtnLcesOgVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Machine_Learning/blob/main/Model_Deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting Setup"
      ],
      "metadata": {
        "id": "ybw8NZZB0S6v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrSHuyl10HZu"
      },
      "outputs": [],
      "source": [
        "#we need Torch 1.12 + and Torchvision 0.13 + for this study\n",
        "try:\n",
        "  import torch, torchvision\n",
        "  assert int(torch.__version__.split(\".\")[1])>=12, \"Torch version should be 1.12 or above\"\n",
        "  assert int(torchvision.__version__.split(\".\")[1])>=13, \"Torch version should be 0.12 or above\"\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")\n",
        "except:\n",
        "  print(\"Available libraries not updated, downloading updated libraries\")\n",
        "  !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  import torch, torchvision\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary"
      ],
      "metadata": {
        "id": "8u4PytKs1Bbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing previously written scripts"
      ],
      "metadata": {
        "id": "Cfck8y9Z1Dd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "id": "s1g_SzQZ1Hqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  #putting in training mode\n",
        "  model.train()\n",
        "  #setup training loss and training accuracy\n",
        "  train_loss,train_acc=0,0\n",
        "\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #send data to target device\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    #forward pass\n",
        "    y_pred=model(x)\n",
        "    #calculate and accumulate losses\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #calculate and accumulate accuracy metric for all batches\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  #getting average loss and accuracy for each batch\n",
        "  train_loss/=len(dataloader)\n",
        "  train_acc/=len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float,float]:\n",
        "  #putting in eval mode\n",
        "  model.eval()\n",
        "  #setup test loss and test accuracy\n",
        "  test_loss,test_acc=0,0\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #loop through dataloader batches\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "      #send data to target device\n",
        "      x,y=x.to(device),y.to(device)\n",
        "      #forward pass\n",
        "      test_pred_logits=model(x)\n",
        "      #calculate and accumulate loss\n",
        "      loss=loss_fn(test_pred_logits,y)\n",
        "      test_loss+=loss.item()\n",
        "      #calculate and accumulate accuracy\n",
        "      test_pred_labels=torch.argmax(torch.softmax(test_pred_logits,dim=1),dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)#can probably also use len(test_pred), not sure both should work i think\n",
        "  #getting average loss and accuracy for each batch\n",
        "  test_acc/=len(dataloader)\n",
        "  test_loss/=len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "#defining functions and various required parameters\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          epochs: int,\n",
        "        device: torch.device) -> Dict[str, list]:\n",
        "  #create empty results dictionary\n",
        "  results={\"train_loss\":[],\n",
        "           \"test_loss\":[],\n",
        "           \"train_acc\":[],\n",
        "           \"test_acc\":[]}\n",
        "  #looping through train_step() and test_step()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss,train_acc=train_step(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "    test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "  #print whats happening\n",
        "    print(\n",
        "        f\"Epoch:{epoch+1}|\"\n",
        "        f\"Train Loss:{train_loss:.4f}|\"\n",
        "        f\"Training Accuracy: {train_acc:.4f}|\"\n",
        "        f\"Test Loss: {test_loss:.4f}|\"\n",
        "        f\"Test Accuracy: {test_acc:.4f}\"\n",
        "    )\n",
        "    #updating result dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "eGwCstRl1Oem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "def save_model(model:torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name:str):\n",
        "  #creating target directory\n",
        "  target_dir_path=Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  #creating model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  #save the model state_dict\n",
        "  print(f\"Saving model to:{model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "51o4fHZe1WJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Device Agnostic Code"
      ],
      "metadata": {
        "id": "ukX_VwDn1ZaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "2zM-CBYN1cme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define function to set random seed"
      ],
      "metadata": {
        "id": "dteGqQ6I1lT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seeds\n",
        "def set_seeds(seed:int=69):\n",
        "  \"set seed whenver required before torch operations. Default seed = 69\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "Dsw1DyJ51o5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get Data"
      ],
      "metadata": {
        "id": "uxv43bSA2pUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "def download_data(source:str,\n",
        "                  destination:str,\n",
        "                  remove_source:bool=True)->Path:\n",
        "  #setup path to data folder\n",
        "  data_path= Path(\"data/\")\n",
        "  image_path=data_path/destination\n",
        "  #check if image folder exists or not, if not prepare it\n",
        "  if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists\")\n",
        "  else:\n",
        "    print(f\"Didnt find {image_path}, creating...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    #the datset that will be used is a formatted dataset being taken from a github file, in general, wont get such formatted data\n",
        "    #download pizza, steak, sushi data in zip file\n",
        "    target_file=Path(source).name\n",
        "    with open(data_path/target_file,\"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(\"Downloading data...\")\n",
        "      f.write(request.content)\n",
        "    #unzip data\n",
        "    with zipfile.ZipFile(data_path/target_file,\"r\") as zip_ref:\n",
        "      print(\"Unzipping food_stuff file...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "    if remove_source:\n",
        "      os.remove(data_path/target_file)\n",
        "  return image_path"
      ],
      "metadata": {
        "id": "N6BUp37y2rVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\", destination='pizza_steak_sushi_20_percent')\n",
        "image_path"
      ],
      "metadata": {
        "id": "3F6XoXOL2sae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/pizza_steak_sushi_20_percent"
      ],
      "metadata": {
        "id": "leR2j-No3uYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating paths to train and test directories\n",
        "train_dir=image_path/\"train\"\n",
        "test_dir=image_path/\"test\""
      ],
      "metadata": {
        "id": "w2kNAiBd3wPL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}