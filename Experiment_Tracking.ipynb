{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6moU+4JKBCoNF4t46Xn8A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Machine_Learning/blob/main/Experiment_Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making required imports"
      ],
      "metadata": {
        "id": "S8_0eiCOhgPP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iNz9JH1hWyB",
        "outputId": "81d81493-a61b-43ee-a5e1-23943af2ec07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available libraries not updated, downloading updated libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Torch version:2.3.0+cu121\n",
            "torchvision version:0.18.0+cu121\n"
          ]
        }
      ],
      "source": [
        "#we need Torch 1.12 + and Torchvision 0.13 + for this study\n",
        "try:\n",
        "  import torch, torchvision\n",
        "  assert int(torch.__version__.split(\".\")[1])>=12, \"Torch version should be 1.12 or above\"\n",
        "  assert int(torchvision.__version__.split(\".\")[1])>=13, \"Torch version should be 0.12 or above\"\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")\n",
        "except:\n",
        "  print(\"Available libraries not updated, downloading updated libraries\")\n",
        "  !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  import torch, torchvision\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary"
      ],
      "metadata": {
        "id": "Qf_amW7Ghi_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IetmO3oiN1o",
        "outputId": "06f6af63-d3d1-4a22-aaf4-68089d847621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  #putting in training mode\n",
        "  model.train()\n",
        "  #setup training loss and training accuracy\n",
        "  train_loss,train_acc=0,0\n",
        "\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #send data to target device\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    #forward pass\n",
        "    y_pred=model(x)\n",
        "    #calculate and accumulate losses\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #calculate and accumulate accuracy metric for all batches\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  #getting average loss and accuracy for each batch\n",
        "  train_loss/=len(dataloader)\n",
        "  train_acc/=len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float,float]:\n",
        "  #putting in eval mode\n",
        "  model.eval()\n",
        "  #setup test loss and test accuracy\n",
        "  test_loss,test_acc=0,0\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #loop through dataloader batches\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "      #send data to target device\n",
        "      x,y=x.to(device),y.to(device)\n",
        "      #forward pass\n",
        "      test_pred_logits=model(x)\n",
        "      #calculate and accumulate loss\n",
        "      loss=loss_fn(test_pred_logits,y)\n",
        "      test_loss+=loss.item()\n",
        "      #calculate and accumulate accuracy\n",
        "      test_pred_labels=torch.argmax(torch.softmax(test_pred_logits,dim=1),dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)#can probably also use len(test_pred), not sure both should work i think\n",
        "  #getting average loss and accuracy for each batch\n",
        "  test_acc/=len(dataloader)\n",
        "  test_loss/=len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "#defining functions and various required parameters\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          epochs: int,\n",
        "        device: torch.device) -> Dict[str, list]:\n",
        "  #create empty results dictionary\n",
        "  results={\"train_loss\":[],\n",
        "           \"test_loss\":[],\n",
        "           \"train_acc\":[],\n",
        "           \"test_acc\":[]}\n",
        "  #looping through train_step() and test_step()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss,train_acc=train_step(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "    test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "  #print whats happening\n",
        "    print(\n",
        "        f\"Epoch:{epoch+1}|\"\n",
        "        f\"Train Loss:{train_loss:.4f}|\"\n",
        "        f\"Training Accuracy: {train_acc:.4f}|\"\n",
        "        f\"Test Loss: {test_loss:.4f}|\"\n",
        "        f\"Test Accuracy: {test_acc:.4f}\"\n",
        "    )\n",
        "    #updating result dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "  return results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0bBhiGmiOz0",
        "outputId": "5d4fc0c8-e291-4303-dd33-710e8c2c5840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import data_setup, engine"
      ],
      "metadata": {
        "id": "zmzTFhVLiUxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make device agnostic code"
      ],
      "metadata": {
        "id": "SjZSeYY7iaXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gEUll03uidW8",
        "outputId": "9c16bc49-b560-48a3-dedc-eb56fcb341fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make function to set seeds"
      ],
      "metadata": {
        "id": "C557pEOViycT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seeds\n",
        "def set_seeds(seed:int=69):\n",
        "  \"set seed whenver required before torch operations. Default seed = 69\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "Nijh2BJ4i09T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting Data"
      ],
      "metadata": {
        "id": "mTp4LPBRjskf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "def download_data(source:str,\n",
        "                  destination:str,\n",
        "                  remove_source:bool=True)->Path:\n",
        "  #setup path to data folder\n",
        "  data_path= Path(\"data/\")\n",
        "  image_path=data_path/destination\n",
        "  #check if image folder exists or not, if not prepare it\n",
        "  if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists\")\n",
        "  else:\n",
        "    print(f\"Didnt find {image_path}, creating...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "    #the datset that will be used is a formatted dataset being taken from a github file, in general, wont get such formatted data\n",
        "    #download pizza, steak, sushi data in zip file\n",
        "    target_file=Path(source).name\n",
        "    with open(data_path/target_file,\"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(\"Downloading data...\")\n",
        "      f.write(request.content)\n",
        "    #unzip data\n",
        "    with zipfile.ZipFile(data_path/target_file,\"r\") as zip_ref:\n",
        "      print(\"Unzipping food_stuff file...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "    if remove_source:\n",
        "      os.remove(data_path/target_file)\n",
        "  return image_path\n",
        "image_path=download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", destination='pizza_steak_sushi')\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsqXTkXAjwXo",
        "outputId": "f7e52a13-42a0-41bc-ac1f-59ce5964ee2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/pizza_steak_sushi"
      ],
      "metadata": {
        "id": "vmdEctlouVin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dataset and dataloaders"
      ],
      "metadata": {
        "id": "4j7TbxlepSej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating paths to train and test directories\n",
        "train_dir=image_path/\"train\"\n",
        "test_dir=image_path/\"test\"\n",
        "#Firstly need to transform images to fit into the model\n",
        "#making transformation manually\n",
        "manual_transforms=transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                           std=[0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                             test_dir=test_dir,\n",
        "                                                                             train_transform=manual_transforms,\n",
        "                                                                             test_transform= manual_transforms,\n",
        "                                                                             batch_size=32)\n",
        "train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "G1cFfeLqpXV1",
        "outputId": "2f5036d2-2c97-4cc1-94d8-009a8a3940be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/pizza_steak_sushi/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-afbb5aa5b6bc>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                            std=[0.229, 0.224, 0.225])\n\u001b[1;32m     10\u001b[0m                                       ])\n\u001b[0;32m---> 11\u001b[0;31m train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir=train_dir,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                                                              \u001b[0mtest_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                              \u001b[0mtrain_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanual_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/data_setup.py\u001b[0m in \u001b[0;36mcreate_dataloaders\u001b[0;34m(train_dir, test_dir, train_transform, test_transform, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     13\u001b[0m ):\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mtesting_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pizza_steak_sushi/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dataloader using automatically created transformation"
      ],
      "metadata": {
        "id": "kYY4Nr5xp7cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating paths to train and test directories\n",
        "train_dir=image_path/\"train\"\n",
        "test_dir=image_path/\"test\"\n",
        "\n",
        "#get a set of pretrained weights\n",
        "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT #DEFAULT gives the best available weights from pretraining on ImageNet\n",
        "\n",
        "#Get transform used to create our pretrained weights\n",
        "auto_transform=weights.transforms()\n",
        "\n",
        "#now, can use auto_transform to create dataloaders\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                             test_dir=test_dir,\n",
        "                                                                             train_transform=manual_transforms,\n",
        "                                                                             test_transform= manual_transforms,\n",
        "                                                                             batch_size=32)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "QaJL6Y1qqrid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting pretrained model EfficientNet_B0 and changing the classifier layer only"
      ],
      "metadata": {
        "id": "kFJ-nJQJKPE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model=torchvision.models.efficientnet_b0(weights=weights).to(device)\n"
      ],
      "metadata": {
        "id": "yufp-2CEKbCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#freeze all parameters in feature extraction layer\n",
        "for param in model.features.parameters():\n",
        "  param.requires_grad()=False\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "#changing classifier layer\n",
        "model.classifier= torch.nn.Sequential(nn.Dropout(p=0.2, inplace=True),\n",
        "                                      nn.Linear(in_features=1280,\n",
        "                                                out_features=len(class_names),\n",
        "                                                bias=True).to(device))\n",
        "from torchinfo import summary\n",
        "\n"
      ],
      "metadata": {
        "id": "CPk7yLCYL-du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "RnQVH7alNdVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "z1dfBMfwNfQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "#create a writer with default settings\n",
        "writer=SummaryWriter()"
      ],
      "metadata": {
        "id": "6kD2YQnXNzFr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}