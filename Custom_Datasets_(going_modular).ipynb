{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiASbkTEiOejfGowCbRuMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a26381e1e7c342a3b4f9ea72c42b3fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae7683d156c64a1e8e3b0c0a80cf1c80",
              "IPY_MODEL_34e738b65a54489c9c9c9c6867965a58",
              "IPY_MODEL_367238cdc5ee4783934b3b6d166648a7"
            ],
            "layout": "IPY_MODEL_72958837a0dc40f38029b4fe36b76c31"
          }
        },
        "ae7683d156c64a1e8e3b0c0a80cf1c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a41da99f5bfe471a85ebbfe4336547e5",
            "placeholder": "​",
            "style": "IPY_MODEL_713db1af380e4cbd9b170cd228a7859a",
            "value": "100%"
          }
        },
        "34e738b65a54489c9c9c9c6867965a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3be68f834854d74a1d2c1f89850e766",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32eabe003f7740769adc7eb2a01b02c0",
            "value": 5
          }
        },
        "367238cdc5ee4783934b3b6d166648a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d821fb489cd4455ba2dbde1576ad006e",
            "placeholder": "​",
            "style": "IPY_MODEL_214f6cf4e2bd4dcb86b9f7d282171ffc",
            "value": " 5/5 [00:11&lt;00:00,  2.26s/it]"
          }
        },
        "72958837a0dc40f38029b4fe36b76c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41da99f5bfe471a85ebbfe4336547e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713db1af380e4cbd9b170cd228a7859a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3be68f834854d74a1d2c1f89850e766": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32eabe003f7740769adc7eb2a01b02c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d821fb489cd4455ba2dbde1576ad006e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214f6cf4e2bd4dcb86b9f7d282171ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Machine_Learning/blob/main/Custom_Datasets_(going_modular).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting data"
      ],
      "metadata": {
        "id": "sIB7tBNgMs_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76JujaCKaW-",
        "outputId": "5df19b1b-d1f0-482b-8d28-5e5d5602fd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/food_stuff directory exists\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "#setup path to data folder\n",
        "data_path= Path(\"data/\")\n",
        "image_path=data_path/\"food_stuff\"\n",
        "#check if image folder exists or not, if not prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists\")\n",
        "else:\n",
        "  print(f\"Didnt find {image_path}, creating...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  #the datset that will be used is a formatted dataset being taken from a github file, in general, wont get such formatted data\n",
        "  #download pizza, steak, sushi data in zip file\n",
        "  with open(data_path/\"food_stuff.zip\",\"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading data...\")\n",
        "    f.write(request.content)\n",
        "  #unzip data\n",
        "  with zipfile.ZipFile(data_path/\"food_stuff.zip\",\"r\") as zip_ref:\n",
        "    print(\"Unzipping food_stuff file...\")\n",
        "    zip_ref.extractall(image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up data in dataloaders\n"
      ],
      "metadata": {
        "id": "oZcYlD-7MwOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6FJMae6OnUr",
        "outputId": "41f71737-957f-47dc-ae21-be69af02a781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), #31 is the most intense\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "#not putting TrivialAugmentWide transform in test transforms\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n"
      ],
      "metadata": {
        "id": "jQrnv1EFWgjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import data_setup\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir= image_path/'train', test_dir= image_path/'test', train_transform=train_transforms, test_transform=test_transforms, batch_size=32)"
      ],
      "metadata": {
        "id": "cgduABqoTZRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyItsNvVZnbN",
        "outputId": "60cbdbc8-6e37-4bed-f065-64af17c9748b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x785975afff10>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7859743c6e60>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing file to build TinyVGG model"
      ],
      "metadata": {
        "id": "r6rWKw6OZ_U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_builder.py\n",
        "#here RGB images instead of grayscale so in_channels=3\n",
        "import torch\n",
        "from torch import nn\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)#stride = kernel size by default\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*16*16,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x=self.classifier(self.conv_block_2(self.conv_block_1(x)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "pDYXntCBZHEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6f048a-9bc4-40c6-e76e-30301d3970cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can import tinyvgg using following code\n",
        "import model_builder\n",
        "import torch\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(43)\n",
        "model_0=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHi6AY9MdtXQ",
        "outputId": "f5c7700f-621c-45ec-b6d4-e93073c05fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0,[1,3,64,64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkS-R7ea_hAZ",
        "outputId": "22ee925d-9228-4a65-f1a3-7ef6d22799a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TinyVGG                                  [1, 3]                    --\n",
              "├─Sequential: 1-1                        [1, 10, 32, 32]           --\n",
              "│    └─Conv2d: 2-1                       [1, 10, 64, 64]           280\n",
              "│    └─ReLU: 2-2                         [1, 10, 64, 64]           --\n",
              "│    └─Conv2d: 2-3                       [1, 10, 64, 64]           910\n",
              "│    └─ReLU: 2-4                         [1, 10, 64, 64]           --\n",
              "│    └─MaxPool2d: 2-5                    [1, 10, 32, 32]           --\n",
              "├─Sequential: 1-2                        [1, 10, 16, 16]           --\n",
              "│    └─Conv2d: 2-6                       [1, 10, 32, 32]           910\n",
              "│    └─ReLU: 2-7                         [1, 10, 32, 32]           --\n",
              "│    └─Conv2d: 2-8                       [1, 10, 32, 32]           910\n",
              "│    └─ReLU: 2-9                         [1, 10, 32, 32]           --\n",
              "│    └─MaxPool2d: 2-10                   [1, 10, 16, 16]           --\n",
              "├─Sequential: 1-3                        [1, 3]                    --\n",
              "│    └─Flatten: 2-11                     [1, 2560]                 --\n",
              "│    └─Linear: 2-12                      [1, 3]                    7,683\n",
              "==========================================================================================\n",
              "Total params: 10,693\n",
              "Trainable params: 10,693\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 6.75\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.82\n",
              "Params size (MB): 0.04\n",
              "Estimated Total Size (MB): 0.91\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing a file engine.py which contains the train_step() and test_step() functions and the train() function which calls both of these functions. Calling it engine as it is the engine of training our model"
      ],
      "metadata": {
        "id": "ABEonOoI0IW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  #putting in training mode\n",
        "  model.train()\n",
        "  #setup training loss and training accuracy\n",
        "  train_loss,train_acc=0,0\n",
        "\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #send data to target device\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    #forward pass\n",
        "    y_pred=model(x)\n",
        "    #calculate and accumulate losses\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #calculate and accumulate accuracy metric for all batches\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  #getting average loss and accuracy for each batch\n",
        "  train_loss/=len(dataloader)\n",
        "  train_acc/=len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float,float]:\n",
        "  #putting in eval mode\n",
        "  model.eval()\n",
        "  #setup test loss and test accuracy\n",
        "  test_loss,test_acc=0,0\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #loop through dataloader batches\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "      #send data to target device\n",
        "      x,y=x.to(device),y.to(device)\n",
        "      #forward pass\n",
        "      test_pred_logits=model(x)\n",
        "      #calculate and accumulate loss\n",
        "      loss=loss_fn(test_pred_logits,y)\n",
        "      test_loss+=loss.item()\n",
        "      #calculate and accumulate accuracy\n",
        "      test_pred_labels=torch.argmax(torch.softmax(test_pred_logits,dim=1),dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)#can probably also use len(test_pred), not sure both should work i think\n",
        "  #getting average loss and accuracy for each batch\n",
        "  test_acc/=len(dataloader)\n",
        "  test_loss/=len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "#defining functions and various required parameters\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          epochs: int,\n",
        "        device: torch.device) -> Dict[str, list]:\n",
        "  #create empty results dictionary\n",
        "  results={\"train_loss\":[],\n",
        "           \"test_loss\":[],\n",
        "           \"train_acc\":[],\n",
        "           \"test_acc\":[]}\n",
        "  #looping through train_step() and test_step()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss,train_acc=train_step(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "    test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "  #print whats happening\n",
        "    print(\n",
        "        f\"Epoch:{epoch+1}|\"\n",
        "        f\"Train Loss:{train_loss:.4f}|\"\n",
        "        f\"Training Accuracy: {train_acc:.4f}|\"\n",
        "        f\"Test Loss: {test_loss:.4f}|\"\n",
        "        f\"Test Accuracy: {test_acc:.4f}\"\n",
        "    )\n",
        "    #updating result dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "  return results\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhiuyrr0_ho",
        "outputId": "ec372c14-0c43-406a-ad64-443d4798838f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets,transforms\n",
        "testing_data=datasets.ImageFolder(root=image_path/'test', transform=test_transforms)\n",
        "testing_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeaZK1ei9R_o",
        "outputId": "e5ae0e02-1e7d-4138-a372-2f80f7026c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ls7dMBWFrnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing engine.py\n",
        "import engine\n",
        "from torch import nn\n",
        "results=engine.train(model=model_0,\n",
        "                    train_dataloader=train_dataloader,\n",
        "                    test_dataloader=test_dataloader,\n",
        "                    optimizer=torch.optim.Adam(params=model_0.parameters(), lr=0.001),\n",
        "                    loss_fn=nn.CrossEntropyLoss(),\n",
        "                    epochs=5,\n",
        "                    device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "a26381e1e7c342a3b4f9ea72c42b3fde",
            "ae7683d156c64a1e8e3b0c0a80cf1c80",
            "34e738b65a54489c9c9c9c6867965a58",
            "367238cdc5ee4783934b3b6d166648a7",
            "72958837a0dc40f38029b4fe36b76c31",
            "a41da99f5bfe471a85ebbfe4336547e5",
            "713db1af380e4cbd9b170cd228a7859a",
            "d3be68f834854d74a1d2c1f89850e766",
            "32eabe003f7740769adc7eb2a01b02c0",
            "d821fb489cd4455ba2dbde1576ad006e",
            "214f6cf4e2bd4dcb86b9f7d282171ffc"
          ]
        },
        "id": "3ohP5Yqn5UyI",
        "outputId": "f1133a01-ebab-493a-d7fa-e307e4f0f0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a26381e1e7c342a3b4f9ea72c42b3fde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1|Train Loss:1.1184|Training Accuracy: 0.2773|Test Loss: 1.1066|Test Accuracy: 0.2604\n",
            "Epoch:2|Train Loss:1.1057|Training Accuracy: 0.2852|Test Loss: 1.1378|Test Accuracy: 0.1979\n",
            "Epoch:3|Train Loss:1.0971|Training Accuracy: 0.2930|Test Loss: 1.1205|Test Accuracy: 0.1875\n",
            "Epoch:4|Train Loss:1.0981|Training Accuracy: 0.2695|Test Loss: 1.1103|Test Accuracy: 0.2604\n",
            "Epoch:5|Train Loss:1.1115|Training Accuracy: 0.3086|Test Loss: 1.1169|Test Accuracy: 0.2708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write file to save model (common practice to store helper functions as utils.py)"
      ],
      "metadata": {
        "id": "NzzFtd8wiQSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "def save_model(model:torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name:str):\n",
        "  #creating target directory\n",
        "  target_dir_path=Path(target_dir)\n",
        "  target_dir_parh.mkdir(parent=True,\n",
        "                        exist_ok=True)\n",
        "  #creating model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  #save the model state_dict\n",
        "  print(f\"Saving model to:{model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "NPfbLD5oiPxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "#save model to file\n",
        "save_model(model=model_0,\n",
        "           target_dir='models',\n",
        "           model_name='model_0(going_modular)')"
      ],
      "metadata": {
        "id": "7DcMlkGibYSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write 1 script to use all above scripts to train, evaluate and save the model"
      ],
      "metadata": {
        "id": "toSh2iiiePST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "#HAVE TO USE ARGPARSE SO THAT THE HYPERPARAMETERS CAN BE SPECIFIED WHILE RUNNING THIS SCRIPT\n",
        "import os\n",
        "import torch\n",
        "import data_setup, engine, model_builder, utils\n",
        "\n",
        "from torchvision import transforms\n",
        "#setup hyperparameters\n",
        "NUM_EPOCHS=5\n",
        "BATCH_SIZE=32\n",
        "HIDDEN_UNITS=10\n",
        "LEARNING_RATE=0.001\n",
        "\n",
        "#setup directories\n",
        "train_dir=\"data/pizza_steak_sushi/train\"\n",
        "test_dir=\"data/pizza_steak_sushi/test\"\n",
        "\n",
        "#setup target device\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#create transforms\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), #31 is the most intense\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "#not putting TrivialAugmentWide transform in test transforms\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir= train_dir,\n",
        "                                                                              test_dir= test_dir,\n",
        "                                                                              train_transform=train_transforms,\n",
        "                                                                              test_transform=test_transforms,\n",
        "                                                                              batch_size=BATCH_SIZE)\n",
        "#build model using model_builder\n",
        "model_0=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "optimizer=torch.optim.Adam(params=model_0.parameters(), lr=LEARNING_RATE)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "#start training from engine.py\n",
        "results=engine.train(model=model_0,\n",
        "                    train_dataloader=train_dataloader,\n",
        "                    test_dataloader=test_dataloader,\n",
        "                    optimizer=optimizer,\n",
        "                    loss_fn=loss_fn,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    device=device)\n",
        "#save model to file\n",
        "save_model(model=model_0,\n",
        "           target_dir='models',\n",
        "           model_name='model_0(going_modular)')"
      ],
      "metadata": {
        "id": "JxxA2ukEfCex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}