{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0CD79Jwhd5mU2+vfan5AS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Machine_Learning/blob/main/Custom_Datasets_(going_modular).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting data"
      ],
      "metadata": {
        "id": "sIB7tBNgMs_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76JujaCKaW-",
        "outputId": "930fbda2-e796-46d3-c9b1-e8f24665c387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/food_stuff directory exists\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "#setup path to data folder\n",
        "data_path= Path(\"data/\")\n",
        "image_path=data_path/\"food_stuff\"\n",
        "#check if image folder exists or not, if not prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists\")\n",
        "else:\n",
        "  print(f\"Didnt find {image_path}, creating...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  #the datset that will be used is a formatted dataset being taken from a github file, in general, wont get such formatted data\n",
        "  #download pizza, steak, sushi data in zip file\n",
        "  with open(data_path/\"food_stuff.zip\",\"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading data...\")\n",
        "    f.write(request.content)\n",
        "  #unzip data\n",
        "  with zipfile.ZipFile(data_path/\"food_stuff.zip\",\"r\") as zip_ref:\n",
        "    print(\"Unzipping food_stuff file...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "#removing zip file\n",
        "os.remove(data_path/\"food_stuff.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up data in dataloaders\n"
      ],
      "metadata": {
        "id": "oZcYlD-7MwOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6FJMae6OnUr",
        "outputId": "296f0ea2-a765-425c-b08c-3a5176e97130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), #31 is the most intense\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "#not putting TrivialAugmentWide transform in test transforms\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n"
      ],
      "metadata": {
        "id": "jQrnv1EFWgjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import data_setup\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir= image_path/'train', test_dir= image_path/'test', train_transform=train_transforms, test_transform=test_transforms, batch_size=32)"
      ],
      "metadata": {
        "id": "cgduABqoTZRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyItsNvVZnbN",
        "outputId": "abdeaa1b-bc1c-43c7-d133-35580a0463b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7f596b438760>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f5a49182fe0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing file to build TinyVGG model"
      ],
      "metadata": {
        "id": "r6rWKw6OZ_U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_builder.py\n",
        "#here RGB images instead of grayscale so in_channels=3\n",
        "import torch\n",
        "from torch import nn\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)#stride = kernel size by default\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*16*16,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x=self.classifier(self.conv_block_2(self.conv_block_1(x)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "pDYXntCBZHEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366b239b-d16b-4fdf-bb49-9ef33c349bfc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can import tinyvgg using following code\n",
        "import model_builder\n",
        "import torch\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(43)\n",
        "model_0=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHi6AY9MdtXQ",
        "outputId": "a731c627-3109-499d-f949-5aa36129d88f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}