{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg7ls9Bad5BTLs11Ywq/Zn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ecdae184384462eb296a655f9f0ba21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b176b4eca534724840c636ee2347205",
              "IPY_MODEL_f00d139954c74fd5a563e074e5a9c2a1",
              "IPY_MODEL_9eaa9d2820e141b58a2d430331f1e227"
            ],
            "layout": "IPY_MODEL_03557d7fba2945b2b44956a07830fab0"
          }
        },
        "0b176b4eca534724840c636ee2347205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a4bea34c6344e7b33df5a1dd2b0d21",
            "placeholder": "​",
            "style": "IPY_MODEL_29baf1f4b43b41a2a5c257d1318dd4ae",
            "value": "100%"
          }
        },
        "f00d139954c74fd5a563e074e5a9c2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e4f0f360234957abbab51ecc53db7b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a72b558222be4ee798d96a62d6417833",
            "value": 5
          }
        },
        "9eaa9d2820e141b58a2d430331f1e227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7e3aad08744dea9b41a2eeccd158dd",
            "placeholder": "​",
            "style": "IPY_MODEL_9271fc8225d9468abf8c4fefd3fda333",
            "value": " 5/5 [00:22&lt;00:00,  4.31s/it]"
          }
        },
        "03557d7fba2945b2b44956a07830fab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a4bea34c6344e7b33df5a1dd2b0d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29baf1f4b43b41a2a5c257d1318dd4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39e4f0f360234957abbab51ecc53db7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72b558222be4ee798d96a62d6417833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad7e3aad08744dea9b41a2eeccd158dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9271fc8225d9468abf8c4fefd3fda333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Machine_Learning/blob/main/Custom_Datasets_(going_modular).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting data"
      ],
      "metadata": {
        "id": "sIB7tBNgMs_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u76JujaCKaW-",
        "outputId": "c0c45cbb-fed3-453f-e8ae-ac02014235e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/food_stuff directory exists\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import os\n",
        "#setup path to data folder\n",
        "data_path= Path(\"data/\")\n",
        "image_path=data_path/\"food_stuff\"\n",
        "#check if image folder exists or not, if not prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists\")\n",
        "else:\n",
        "  print(f\"Didnt find {image_path}, creating...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  #the datset that will be used is a formatted dataset being taken from a github file, in general, wont get such formatted data\n",
        "  #download pizza, steak, sushi data in zip file\n",
        "  with open(data_path/\"food_stuff.zip\",\"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading data...\")\n",
        "    f.write(request.content)\n",
        "  #unzip data\n",
        "  with zipfile.ZipFile(data_path/\"food_stuff.zip\",\"r\") as zip_ref:\n",
        "    print(\"Unzipping food_stuff file...\")\n",
        "    zip_ref.extractall(image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up data in dataloaders\n"
      ],
      "metadata": {
        "id": "oZcYlD-7MwOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6FJMae6OnUr",
        "outputId": "e903613c-668c-4fb7-c1f3-27a57494834e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), #31 is the most intense\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "#not putting TrivialAugmentWide transform in test transforms\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n"
      ],
      "metadata": {
        "id": "jQrnv1EFWgjt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import data_setup\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir= image_path/'train', test_dir= image_path/'test', train_transform=train_transforms, test_transform=test_transforms, batch_size=32)"
      ],
      "metadata": {
        "id": "cgduABqoTZRH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyItsNvVZnbN",
        "outputId": "04c24c46-726e-47fd-8817-7836546b9019"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b8693eb1b10>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b8693eb1330>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing file to build TinyVGG model"
      ],
      "metadata": {
        "id": "r6rWKw6OZ_U_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_builder.py\n",
        "#here RGB images instead of grayscale so in_channels=3\n",
        "import torch\n",
        "from torch import nn\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape:int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1\n",
        "                  ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2=nn.Sequential(\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units,hidden_units,kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)#stride = kernel size by default\n",
        "    )\n",
        "    self.classifier=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*16*16,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x=self.classifier(self.conv_block_2(self.conv_block_1(x)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "pDYXntCBZHEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "176803f1-22a1-4cf7-8cb5-d90a47c68cd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#can import tinyvgg using following code\n",
        "import model_builder\n",
        "import torch\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(43)\n",
        "model_0=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHi6AY9MdtXQ",
        "outputId": "a1a172f1-2540-42ab-d6cd-4b9fa866b712"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0,[1,3,64,64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkS-R7ea_hAZ",
        "outputId": "44245fe0-a8c6-4de0-b69c-0abfa6506076"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "TinyVGG                                  [1, 3]                    --\n",
              "├─Sequential: 1-1                        [1, 10, 32, 32]           --\n",
              "│    └─Conv2d: 2-1                       [1, 10, 64, 64]           280\n",
              "│    └─ReLU: 2-2                         [1, 10, 64, 64]           --\n",
              "│    └─Conv2d: 2-3                       [1, 10, 64, 64]           910\n",
              "│    └─ReLU: 2-4                         [1, 10, 64, 64]           --\n",
              "│    └─MaxPool2d: 2-5                    [1, 10, 32, 32]           --\n",
              "├─Sequential: 1-2                        [1, 10, 16, 16]           --\n",
              "│    └─Conv2d: 2-6                       [1, 10, 32, 32]           910\n",
              "│    └─ReLU: 2-7                         [1, 10, 32, 32]           --\n",
              "│    └─Conv2d: 2-8                       [1, 10, 32, 32]           910\n",
              "│    └─ReLU: 2-9                         [1, 10, 32, 32]           --\n",
              "│    └─MaxPool2d: 2-10                   [1, 10, 16, 16]           --\n",
              "├─Sequential: 1-3                        [1, 3]                    --\n",
              "│    └─Flatten: 2-11                     [1, 2560]                 --\n",
              "│    └─Linear: 2-12                      [1, 3]                    7,683\n",
              "==========================================================================================\n",
              "Total params: 10,693\n",
              "Trainable params: 10,693\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 6.75\n",
              "==========================================================================================\n",
              "Input size (MB): 0.05\n",
              "Forward/backward pass size (MB): 0.82\n",
              "Params size (MB): 0.04\n",
              "Estimated Total Size (MB): 0.91\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writing a file engine.py which contains the train_step() and test_step() functions and the train() function which calls both of these functions. Calling it engine as it is the engine of training our model"
      ],
      "metadata": {
        "id": "ABEonOoI0IW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  #putting in training mode\n",
        "  model.train()\n",
        "  #setup training loss and training accuracy\n",
        "  train_loss,train_acc=0,0\n",
        "\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #send data to target device\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    #forward pass\n",
        "    y_pred=model(x)\n",
        "    #calculate and accumulate losses\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #calculate and accumulate accuracy metric for all batches\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  #getting average loss and accuracy for each batch\n",
        "  train_loss/=len(dataloader)\n",
        "  train_acc/=len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float,float]:\n",
        "  #putting in eval mode\n",
        "  model.eval()\n",
        "  #setup test loss and test accuracy\n",
        "  test_loss,test_acc=0,0\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #loop through dataloader batches\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "      #send data to target device\n",
        "      x,y=x.to(device),y.to(device)\n",
        "      #forward pass\n",
        "      test_pred_logits=model(x)\n",
        "      #calculate and accumulate loss\n",
        "      loss=loss_fn(test_pred_logits,y)\n",
        "      test_loss+=loss.item()\n",
        "      #calculate and accumulate accuracy\n",
        "      test_pred_labels=torch.argmax(torch.softmax(test_pred_logits,dim=1),dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)#can probably also use len(test_pred), not sure both should work i think\n",
        "  #getting average loss and accuracy for each batch\n",
        "  test_acc/=len(dataloader)\n",
        "  test_loss/=len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "#defining functions and various required parameters\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          epochs: int,\n",
        "        device: torch.device) -> Dict[str, list]:\n",
        "  #create empty results dictionary\n",
        "  results={\"train_loss\":[],\n",
        "           \"test_loss\":[],\n",
        "           \"train_acc\":[],\n",
        "           \"test_acc\":[]}\n",
        "  #looping through train_step() and test_step()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss,train_acc=train_step(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "    test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "  #print whats happening\n",
        "    print(\n",
        "        f\"Epoch:{epoch+1}|\"\n",
        "        f\"Train Loss:{train_loss:.4f}|\"\n",
        "        f\"Training Accuracy: {train_acc:.4f}|\"\n",
        "        f\"Test Loss: {test_loss:.4f}|\"\n",
        "        f\"Test Accuracy: {test_acc:.4f}\"\n",
        "    )\n",
        "    #updating result dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "  return results\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhiuyrr0_ho",
        "outputId": "ada9d08e-be05-4d1a-9857-2d9382aeae14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets,transforms\n",
        "testing_data=datasets.ImageFolder(root=image_path/'test', transform=test_transforms)\n",
        "testing_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeaZK1ei9R_o",
        "outputId": "03fe9fa3-52f7-4cc0-fc95-2fda5d77a048"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ls7dMBWFrnL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing engine.py\n",
        "import engine\n",
        "from torch import nn\n",
        "results=engine.train(model=model_0,\n",
        "                    train_dataloader=train_dataloader,\n",
        "                    test_dataloader=test_dataloader,\n",
        "                    optimizer=torch.optim.Adam(params=model_0.parameters(), lr=0.001),\n",
        "                    loss_fn=nn.CrossEntropyLoss(),\n",
        "                    epochs=5,\n",
        "                    device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "3ecdae184384462eb296a655f9f0ba21",
            "0b176b4eca534724840c636ee2347205",
            "f00d139954c74fd5a563e074e5a9c2a1",
            "9eaa9d2820e141b58a2d430331f1e227",
            "03557d7fba2945b2b44956a07830fab0",
            "03a4bea34c6344e7b33df5a1dd2b0d21",
            "29baf1f4b43b41a2a5c257d1318dd4ae",
            "39e4f0f360234957abbab51ecc53db7b",
            "a72b558222be4ee798d96a62d6417833",
            "ad7e3aad08744dea9b41a2eeccd158dd",
            "9271fc8225d9468abf8c4fefd3fda333"
          ]
        },
        "id": "3ohP5Yqn5UyI",
        "outputId": "a8ce0970-d7c0-4caf-d337-f98bcb9425a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ecdae184384462eb296a655f9f0ba21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1|Train Loss:1.1184|Training Accuracy: 0.2773|Test Loss: 1.1066|Test Accuracy: 0.2604\n",
            "Epoch:2|Train Loss:1.1057|Training Accuracy: 0.2852|Test Loss: 1.1378|Test Accuracy: 0.1979\n",
            "Epoch:3|Train Loss:1.0971|Training Accuracy: 0.2930|Test Loss: 1.1205|Test Accuracy: 0.1875\n",
            "Epoch:4|Train Loss:1.0981|Training Accuracy: 0.2695|Test Loss: 1.1103|Test Accuracy: 0.2604\n",
            "Epoch:5|Train Loss:1.1115|Training Accuracy: 0.3086|Test Loss: 1.1169|Test Accuracy: 0.2708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write file to save model (common practice to store helper functions as utils.py)"
      ],
      "metadata": {
        "id": "NzzFtd8wiQSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "def save_model(model:torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name:str):\n",
        "  #creating target directory\n",
        "  target_dir_path=Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  #creating model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  #save the model state_dict\n",
        "  print(f\"Saving model to:{model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "NPfbLD5oiPxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9c199e-c822-4f9b-a5a0-afb82803f44a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utils\n",
        "#save model to file\n",
        "utils.save_model(model=model_0,\n",
        "           target_dir='models',\n",
        "           model_name='model_0(going_modular).pth')"
      ],
      "metadata": {
        "id": "7DcMlkGibYSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98e856c-9dc6-4aa3-9b11-9ac8cdcfd816"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to:models/model_0(going_modular).pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write 1 script to use all above scripts to train, evaluate and save the model"
      ],
      "metadata": {
        "id": "toSh2iiiePST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import torch\n",
        "import data_setup, engine, model_builder, utils\n",
        "from torchvision import transforms\n",
        "#setup hyperparameters\n",
        "NUM_EPOCHS=5\n",
        "BATCH_SIZE=32\n",
        "HIDDEN_UNITS=10\n",
        "LEARNING_RATE=0.001\n",
        "\n",
        "#setup directories\n",
        "train_dir=\"data/pizza_steak_sushi/train\"\n",
        "test_dir=\"data/pizza_steak_sushi/test\"\n",
        "\n",
        "#setup target device\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#create transforms\n",
        "train_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31), #31 is the most intense\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "#not putting TrivialAugmentWide transform in test transforms\n",
        "test_transforms=transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()#using this gets all values between 0 & 1\n",
        "])\n",
        "train_dataloader, test_dataloader, class_names= data_setup.create_dataloaders(train_dir= train_dir,\n",
        "                                                                              test_dir= test_dir,\n",
        "                                                                              train_transform=train_transforms,\n",
        "                                                                              test_transform=test_transforms,\n",
        "                                                                              batch_size=BATCH_SIZE)\n",
        "#build model using model_builder\n",
        "model_0=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "optimizer=torch.optim.Adam(params=model_0.parameters(), lr=LEARNING_RATE)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "#start training from engine.py\n",
        "results=engine.train(model=model_0,\n",
        "                    train_dataloader=train_dataloader,\n",
        "                    test_dataloader=test_dataloader,\n",
        "                    optimizer=optimizer,\n",
        "                    loss_fn=loss_fn,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    device=device)\n",
        "#save model to file\n",
        "save_model(model=model_0,\n",
        "           target_dir='models',\n",
        "           model_name='model_0(going_modular)')"
      ],
      "metadata": {
        "id": "JxxA2ukEfCex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "934954bb-58da-48dc-fa19-c7cb9315354d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile predict.py\n",
        "import torch\n",
        "import argparse, torchvision, model_builder\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use the TkAgg backend\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#setup target device\n",
        "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#create a parser\n",
        "parser=argparse.ArgumentParser()\n",
        "#get an image path\n",
        "parser.add_argument(\"--image\",\n",
        "                    help=\"target image filepath to predict on\",\n",
        "                    type=str)\n",
        "#get a model path\n",
        "parser.add_argument(\"--model_path\",\n",
        "                    default='models/model_0(going_modular).pth',\n",
        "                    type=str,\n",
        "                    help='filepath of target model to use for prediction')\n",
        "args= parser.parse_args()\n",
        "IMG_PATH=args.image\n",
        "print(f\"Predicting on {IMG_PATH}\")\n",
        "class_names=['pizza', 'steak', 'sushi']\n",
        "#Defining function to load the model\n",
        "def load_model(filepath=args.model_path):\n",
        "  model=model_builder.TinyVGG(input_shape=3, hidden_units=10, output_shape=3)\n",
        "  #loading in saved state dictionary of trained model\n",
        "  model.load_state_dict(torch.load(filepath))\n",
        "  return model\n",
        "def predict_on_img(image=IMG_PATH, filepath=args.model_path):\n",
        "  model= load_model(filepath)\n",
        "  #load image form image path and convert tensor values to float32(same as model)\n",
        "  target_image=torchvision.io.read_image(str(IMG_PATH)).type(torch.float32)\n",
        "  #divide pixel values to get them between 0 and 1\n",
        "  target_image/=255\n",
        "  #apply transform\n",
        "  transform= torchvision.transforms.Resize(size=(64,64))\n",
        "  target_image=transform(target_image)\n",
        "  #model evaluation and inference mode\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    #adding extra dimension (which represents batch size)\n",
        "    target_image=target_image.unsqueeze(dim=0)\n",
        "    #send image to device and make prediction\n",
        "    target_image_pred= model(target_image.to(device))\n",
        "    #logits to prediction probabilities\n",
        "    target_img_pred_prob=torch.softmax(target_image_pred, dim=1)\n",
        "    #prediction probabilities to prediction labels\n",
        "    target_img_pred_label=torch.argmax(target_img_pred_prob, dim=1)\n",
        "    #plot the image alongside prediction and prediciton probabilities\n",
        "    plt.imshow(target_image.squeeze().permute(1,2,0))\n",
        "    if class_names:\n",
        "      title=f\"Pred:{class_names[target_img_pred_label.cpu()]} | Prob:{target_img_pred_prob.max().cpu():.3f}\"\n",
        "    else:\n",
        "      title=f\"Pred:{target_img_pred_label.cpu()} | Prob:{target_img_pred_prob.max().cpu():.3f}\"\n",
        "  print(title)\n",
        "  plt.title(title)\n",
        "  plt.axis(False)\n",
        "  plt.show()\n",
        "if __name__==\"__main__\":#when this script is being run\n",
        "  predict_on_img()"
      ],
      "metadata": {
        "id": "QcUk9C72UxTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efcde3e-4fee-42cd-853b-b73328d968d1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --image /content/data/food_stuff/test/sushi/1434806.jpg # I DONT KNOW WHY THIS IS NOT PRINTING"
      ],
      "metadata": {
        "id": "FzRktza6gLkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd509dd-0119-4f58-dbcb-bb5d5fe9d6d1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting on /content/data/food_stuff/test/sushi/1434806.jpg\n",
            "Pred:pizza | Prob:0.347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can also use Argparse in train.py script to add arguments for models and hidden units etc"
      ],
      "metadata": {
        "id": "E__iJ1EprWFL"
      }
    }
  ]
}